import torch
import torch.nn as nn
import torch.nn.functional as F
import pandas as pd
import numpy as np
import os
import timm
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold
from torch.utils.data import Dataset,DataLoader
from scipy.interpolate import griddata
from transformers import get_cosine_schedule_with_warmup
from sklearn.metrics import roc_auc_score
from torch.utils.data import Subset
from sklearn.preprocessing import StandardScaler
from category_encoders import CatBoostEncoder

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")

train_X = train.drop(columns=['Class'])
train_Y = train['Class'].apply(lambda x:1 if x=='NG' else 0)
test_X = test.drop(columns=['ID'])

x_loc = [f"X{i+1}" for i in range(5)]
y_loc = [f"Y{i+1}" for i in range(5)]
g = [f"G{i+1}" for i in range(4)]
x_fem = [f"x{i}" for i in range(256)]
y_fem = [f"y{i}" for i in range(256)]
p_fem = [f"p{i}" for i in range(256)]

cols = x_fem + y_fem + p_fem + x_loc + y_loc

def g_statis(df):
    df['G_sum'] = df[g].sum(axis=1)
    df['G_mean'] = df[g].mean(axis=1)
    df['G_std'] = df[g].std(axis=1, ddof=0)
    df['G_max'] = df[g].max(axis=1)
    df['G_min'] = df[g].min(axis=1)
    df['G_range'] = df['G_max'] - df['G_min']
    eps = 1e-6
    df['G1_div_G4'] = df['G1'] / (df['G4'].abs() + eps)
    df['G2_div_G3'] = df['G2'] / (df['G3'].abs() + eps)
    return df

train_X = g_statis(train_X)
test_X  = g_statis(test_X)

g1 = train_X.drop(columns=cols)
g2 = test_X.drop(columns=cols)

cat_list = g1.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()
num_list = sorted(list(set(g1.columns) - set(cat_list)))

sgkf = StratifiedKFold(n_splits = 5, shuffle=True, random_state=2)

for train_idx, val_idx in sgkf.split(train_X, train_Y):
    break

g1_train = g1.iloc[train_idx]
g1_val   = g1.iloc[val_idx]
y_train  = train_Y.iloc[train_idx]
y_val    = train_Y.iloc[val_idx]
scaler = StandardScaler().fit(g1_train[num_list])

cbe = CatBoostEncoder(cols=cat_list, random_state=42, sigma=1.0)
cbe.fit(g1_train[cat_list], y_train)

def preprocess(dataset):
    Xc = cbe.transform(dataset[cat_list]).values.astype("float32")
    Xn = scaler.transform(dataset[num_list]).astype("float32")
    return np.concatenate([Xc, Xn], axis=1)

df = train[cols]
df_test = test[cols]

g_train = preprocess(g1).astype("float32")
g_test = preprocess(g2).astype("float32")

output = "fem_depth"
os.makedirs(output,exist_ok=True)

K = len(x_loc)

def depth_image(x,y,p, x_loc, y_loc, radius=0, H=16, W=16,
                use_gaussian_mask=True):
    x = np.asarray(x, dtype=float)
    y = np.asarray(y, dtype=float)
    p = np.asarray(p, dtype=float)

    x_min, x_max = x.min(), x.max()
    y_min, y_max = y.min(), y.max()

    grid_x, grid_y = np.meshgrid(
        np.linspace(x_min, x_max, W),
        np.linspace(y_min, y_max, H)
    )

    points = np.stack([x, y], axis=1)

    img = griddata(points, p, (grid_x, grid_y),
                   method='cubic',
                   fill_value=p.mean())

    depth_np = img.astype("float32")
    depth = torch.from_numpy(depth_np).to(device)  # [H, W]

    x_g = torch.linspace(x_min, x_max, W, device=depth.device) \
        .view(1, W).repeat(H, 1)  # [H, W]

    y_g = torch.linspace(y_min, y_max, H, device=depth.device) \
        .view(H, 1).repeat(1, W)

    masks = []
    for Xi, Yi in zip(x_loc, y_loc):
        Xi = float(Xi)
        Yi = float(Yi)
        dist2 = (x_g -Xi)**2 + (y_g - Yi)**2

        mask = (dist2 <= radius**2).float()
        masks.append(mask)

    loc_masks = torch.stack(masks, dim=0)

    xs = torch.linspace(-1, 1, W, device=depth.device).view(1, W).repeat(H, 1)
    ys = torch.linspace(-1, 1, H, device=depth.device).view(H, 1).repeat(1, W)
    coord_x = xs.unsqueeze(0)  # [1, H, W]
    coord_y = ys.unsqueeze(0)

    depth_ch = depth.unsqueeze(0)  # (1, H, W)
    input_tensor = torch.cat([depth_ch, loc_masks, coord_x, coord_y], dim=0)

    return input_tensor

def save_image(x, y, p, x_loc, y_loc, filename="depth+mask.png"):
    t = depth_image(x, y, p, x_loc, y_loc)
    depth = t[0].numpy()
    plt.imsave(filename, depth, cmap="gray")
    print(f"saved to {filename}")

depth_tensor_list = []

X_arr = df[x_fem].to_numpy()
Y_arr = df[y_fem].to_numpy()
P_arr = df[p_fem].to_numpy()
X_loc = df[x_loc].to_numpy()
Y_loc = df[y_loc].to_numpy()

for i in range(len(df)):
    depth_tensor_list.append(
        depth_image(
            X_arr[i], Y_arr[i], P_arr[i],
            X_loc[i], Y_loc[i], radius=1, H=16, W=16
        )
    )
depth_tensor = torch.stack(depth_tensor_list, dim=0)
print("depth_tensor shape (train):", depth_tensor.shape)

depth_tensor_test_list = []

X_arr_test = df_test[x_fem].to_numpy()
Y_arr_test = df_test[y_fem].to_numpy()
P_arr_test = df_test[p_fem].to_numpy()
X_loc_test = df_test[x_loc].to_numpy()
Y_loc_test = df_test[y_loc].to_numpy()

for i in range(len(df_test)):
    depth_tensor_test_list.append(
        depth_image(
            X_arr_test[i], Y_arr_test[i], P_arr_test[i],
            X_loc_test[i], Y_loc_test[i], radius=1, H=16, W=16
        )
    )
depth_tensor_test = torch.stack(depth_tensor_test_list, dim=0)
print("depth_tensor shape (test):", depth_tensor_test.shape)

#이미지 저장
# for i in range(len(df)):
#     x_row = X_arr[i]
#     y_row = Y_arr[i]
#     p_row = P_arr[i]
#     xloc_row = X_loc[i]
#     yloc_row = Y_loc[i]
#
#     filename = f"depth_{i:04d}.png"
#     save_image(x_row, y_row, p_row, xloc_row, yloc_row, filename)

class SwinTransformer(nn.Module):
    def __init__(self, img_size=32, coord_dim=28, coord_emb_dim=96, in_chans=1+K+2):
        super().__init__()
        self.img_size = img_size

        self.backbone = timm.create_model(
            'swin_tiny_patch4_window7_224',
            pretrained=True,
            in_chans=in_chans,
            num_classes=0,  # head 제거 → feature만 뽑음
            global_pool="avg",
            img_size=img_size,
        )
        backbone_dim = self.backbone.num_features

        self.coord_mlp = nn.Sequential(
            nn.Linear(coord_dim, coord_emb_dim),
            nn.ReLU(),
            nn.BatchNorm1d(coord_emb_dim),
        )

        self.classifier = nn.Sequential(
            nn.Linear(backbone_dim + coord_emb_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(128, 1),
        )

    def forward_features(self, x, loc):
        if x.shape[-1] != self.img_size or x.shape[-2] != self.img_size:
            x = F.interpolate(
                x,
                size=(self.img_size, self.img_size),
                mode="bilinear",
                align_corners=False,
            )  # [B, C, 32, 32]

        img_feat = self.backbone(x)  # [B, backbone_dim]
        loc_feat = self.coord_mlp(loc)

        fused_feat = torch.cat([img_feat, loc_feat], dim=1)  # [B, backbone_dim+coord_emb_dim]
        return fused_feat

    def forward(self, x, loc):
        feat = self.forward_features(x, loc)
        logit = self.classifier(feat)
        return logit.squeeze(1)   #[B]

depth_channel = depth_tensor[:, 0, :, :]  # [N,H,W]
depth_mean = depth_channel.mean().item()
depth_std  = depth_channel.std().item()

class FEMDepthDataset(Dataset):
    def __init__(self, depth_tensor, g_array, labels, depth_mean, depth_std):
        self.X = depth_tensor
        self.g = torch.tensor(g_array, dtype=torch.float32)
        self.y = torch.tensor(labels).float()
        self.depth_mean = depth_mean
        self.depth_std = depth_std

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        x = self.X[idx].clone()
        g = self.g[idx]
        y = self.y[idx]

        x[0] = (x[0] - self.depth_mean) / (self.depth_std + 1e-6)
        return x, g, y

class FEMDepthTestDataset(Dataset):
    def __init__(self, depth_tensor_test, g_array, depth_mean, depth_std):
        self.X = depth_tensor_test
        self.g = torch.tensor(g_array, dtype=torch.float32)
        self.depth_mean = depth_mean
        self.depth_std = depth_std

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        x = self.X[idx].clone()
        g = self.g[idx]

        x[0] = (x[0] - self.depth_mean) / (self.depth_std + 1e-6)
        return x, g

class EarlyStopping:
    def __init__(self, patience=5, mode="max", delta=1e-4, path="auc.pth"):
        self.patience=patience
        self.mode=mode
        self.delta=delta
        self.path=path

        self.best_score=None
        self.counter=0
        self.early_stop=False

    def __call__(self, metric, model):
        score=metric

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(model)
        else:
            if self.mode == "max":
                if score > self.best_score+self.delta:
                    self.best_score = score
                    self.save_checkpoint(model)
                    self.counter=0
                else:
                    self.counter += 1
                    if self.counter >= self.patience:
                        self.early_stop = True

    def save_checkpoint(self, model):
        torch.save(model.state_dict(), self.path)
        print(f"best_score = {self.best_score:.4f}")

def get_swin_latent_features(model, device,
                             depth_tensor, g_train, train_Y,
                             depth_tensor_test, g_test,
                             depth_mean, depth_std,
                             batch_size=64):
    dataset = FEMDepthDataset(depth_tensor, g_train, train_Y.values,
                              depth_mean=depth_mean, depth_std=depth_std)
    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)

    test_dataset = FEMDepthTestDataset(depth_tensor_test, g_test,
                                       depth_mean, depth_std)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    X_img_train, y_from_loader = extract_latent(train_loader, model, device)
    X_img_test, _ = extract_latent(test_loader, model, device)

    return X_img_train, X_img_test, y_from_loader

def extract_latent(loader, model, device):

    model.eval()
    all_feat = []
    all_labels = []

    with torch.no_grad():
        for batch in loader:
            if len(batch) == 3:
                images, g_batch, labels = batch
            else:
                images, g_batch = batch
                labels = None

            images = images.to(device)
            g_batch = g_batch.to(device)

            # Swin 모델의 latent feature 추출
            feat = model.forward_features(images, g_batch)  # [B, D]
            all_feat.append(feat.cpu().numpy())

            if labels is not None:
                all_labels.append(labels.numpy())

    X_feat = np.concatenate(all_feat, axis=0)
    y = np.concatenate(all_labels, axis=0) if all_labels else None

    return X_feat, y

def get_predictions(loader, model, device):
    all_probs = []
    all_labels = []
    model.eval()
    with torch.no_grad():
        for batch in loader:
            if len(batch) == 3:
                images, g_batch, labels = batch
            else:
                images, g_batch = batch
                labels = None
            images    = images.to(device)
            g_batch = g_batch.to(device)

            logits = model(images, g_batch)
            probs  = torch.sigmoid(logits)  # [B]

            all_probs.append(probs.cpu().numpy().ravel())
            if labels is not None:
                all_labels.append(labels.cpu().numpy().ravel())

    all_probs  = np.concatenate(all_probs)
    if len(all_labels) > 0:
        all_labels = np.concatenate(all_labels)
    else:
        all_labels = None
    return all_probs, all_labels

num_epochs = 35

dataset = FEMDepthDataset(depth_tensor, g_train, train_Y.values, depth_mean=depth_mean, depth_std=depth_std)

test_dataset = FEMDepthTestDataset(depth_tensor_test, g_test, depth_mean, depth_std)
test_loader = DataLoader(test_dataset,batch_size=64,shuffle=False)

train_d = Subset(dataset, train_idx)
val_d = Subset(dataset, val_idx)

train_loader = DataLoader(train_d, batch_size=64, shuffle=True)
val_loader = DataLoader(val_d, batch_size=64, shuffle=False)

g_dim = g_train.shape[1]

model = SwinTransformer(in_chans=1+K+2).to(device)
criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.7], dtype=torch.float32).to(device))
optimizer = torch.optim.AdamW([
        {"params": model.backbone.parameters(),
         "lr": 5e-5},          # Swin backbone

        {"params": list(model.coord_mlp.parameters()) +
                   list(model.classifier.parameters()),
         "lr": 1e-4},          # tabular + classifier
    ], weight_decay=0.05)

num_training_steps = num_epochs * len(train_loader)
scheduler = get_cosine_schedule_with_warmup(optimizer,num_warmup_steps=int(0.1 * num_training_steps),num_training_steps=num_training_steps)

early_stopping = EarlyStopping(
    patience=10,
    mode="max",
    delta=1e-4,
    path="best_swin_auc.pth"
)

train_losses = []
val_aucs = []

for epoch in range(1, num_epochs + 1):
    model.train()
    total_loss = 0.0
    for images, g_batch, labels in train_loader:
        images = images.to(device)  # [B,1,H,W]
        g_batch = g_batch.to(device)  # [B,14]
        labels = labels.to(device)  # [B]

        optimizer.zero_grad()
        logits = model(images, g_batch)
        loss = criterion(logits, labels)

        loss.backward()
        optimizer.step()
        scheduler.step()

        total_loss += loss.item() * images.size(0)

    train_losses.append(total_loss / len(train_d))
    print(f"Epoch {epoch} mean loss:", total_loss / len(train_d))

    train_p, train_l = get_predictions(train_loader, model, device)
    train_a = roc_auc_score(train_l, train_p)
    val_p, val_l = get_predictions(val_loader, model, device)
    val_a = roc_auc_score(val_l, val_p)

    print(f"Epoch {epoch:02d} | train_auc = {train_a:.4f} | val_auc = {val_a:.4f}")

    early_stopping(val_a, model)
    if early_stopping.early_stop:
        break

best_model_path = "best_swin_auc.pth"
model.load_state_dict(torch.load(best_model_path, map_location=device))
model.to(device)